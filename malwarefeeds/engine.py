# -*- coding: utf-8 -*-
"""An Engine to handle the malware feeds."""

import re
from typing import Tuple

import feedparser

from requests import get


class Engine(object):
    """An Engine to handle the malware feeds."""

    def __init__(self):
        """Initialize the Engine object."""
        self.malcode = []
        self.mdl = []
        self.vxvault = []
        self.ransomware = []
        self._headers = {'User-agent': 'Mozilla/5.0 (X11; U; Linux i686)'}
        self._feeds = {
            'malcode': {
                'url': 'http://malc0de.com/rss',
                'parser': self._parse_xml_list_desc,
                'body': ''
            },
            'mdl': {
                'url': 'http://www.malwaredomainlist.com/hostslist/mdl.xml',
                'parser': self._parse_xml_list_desc,
                'body': ''
            },
            'vxvault': {
                'url': 'http://vxvault.net/URL_List.php',
                'parser': self._parse_txt_file,
                'body': ''
            },
            'ransomware': {
                'url': 'https://ransomwaretracker.abuse.ch/downloads/RW_URLBL.txt',
                'parser': self._parse_xml_list_desc,
                'body': ''
            }
        }

    def download(self):
        """
        Fetch the content from all feeds.

        raise: ConnectionError
        """
        for feed in self._feeds.keys():
            url = self._feeds.get(feed).get('url')
            body = get(url, headers=self._headers).content
            self._feeds.get(feed)['body'] = body

    def get_urls(self) -> Tuple[str, str]:
        """Get the urls from feeds."""
        for feed in self._feeds.keys():
            body = self._feeds.get(feed).get('body')
            parser = self._feeds.get(feed).get('parser')
            for url in parser(body):
                yield feed, url

    def _parse_xml_list_desc(self, response):
        """Parse a XML Feed."""
        feed = feedparser.parse(response)

        for entry in feed.entries:
            desc = entry.description.split(' ')
            url = desc[1].rstrip(',')

            if url == '':
                continue

            if url == '-' and len(desc) >= 5:
                url = desc[4].rstrip(',')
            # troca &amp; por &
            url = re.sub('&amp;', '&', url)
            # senao tem http no inicio, coloca
            if not re.match('http', url):
                url = 'http://' + url
            yield url

    def _parse_txt_file(self, response):
        """Parse text files and split it."""
        splitter = '\r\n'
        if response:
            if splitter not in response:
                splitter = '\n'
            for url in response.split(splitter):
                if url.startswith('http'):
                    yield url
